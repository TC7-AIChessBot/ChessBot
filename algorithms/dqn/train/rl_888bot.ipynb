{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install keras-rl2\n",
    "! pip install chess\n",
    "! pip install python-chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten,\\\n",
    "     Input,BatchNormalization, Dropout, Conv2D, Add, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import Policy\n",
    "\n",
    "import chess\n",
    "import chess.engine\n",
    "from sys import platform\n",
    "import os\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(0, '../../bot_model/')\n",
    "# from  model888 import get_model888\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drive.MyDrive.Data.Chess.model888 import get_model888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "os.system('chmod +x drive/MyDrive/Data/Chess/stockfish_14.1_linux_x64')\n",
    "engine = chess.engine.SimpleEngine.popen_uci(r\"drive/MyDrive/Data/Chess/stockfish_14.1_linux_x64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# if platform == \"linux\" or platform == \"linux2\":\n",
    "#     os.system('chmod +x ../stockfish/stockfish_14.1_linux_x64')\n",
    "#     engine = chess.engine.SimpleEngine.popen_uci(r\"../stockfish/stockfish_14.1_linux_x64\")\n",
    "# elif platform == \"win32\":\n",
    "#     engine = chess.engine.SimpleEngine.popen_uci(r\"../stockfish/stockfish_14.1_win_32bit.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_move(env):\n",
    "    result = engine.play(env.env, chess.engine.Limit(time=0.05))\n",
    "    return result.move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SHAPE = (8, 8, 8)\n",
    "NB_ACTIONS = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x,square,map):\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if square[i][j]==map:\n",
    "                x[i][j]=1\n",
    "            elif square[i][j] == -map:\n",
    "                x[i][j]=-1   \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessEnv:\n",
    "    '''\n",
    "    state - obser: ndarray - (65,): [:65] is flatten from int_board; [65] is color of bot; 1 is white and -1 is black\n",
    "    step: int. step_range = (0, 4096) , is encoded from square A to square B (64 x 64 val)\n",
    "    reward: int\n",
    "    '''\n",
    "\n",
    "    mapped = {\n",
    "            'P': 10,     # White Pawn\n",
    "            'p': -10,    # Black Pawn\n",
    "            'N': 20,     # White Knight\n",
    "            'n': -20,    # Black Knight\n",
    "            'B': 30,     # White Bishop\n",
    "            'b': -30,    # Black Bishop\n",
    "            'R': 40,     # White Rook\n",
    "            'r': -40,    # Black Rook\n",
    "            'Q': 50,     # White Queen\n",
    "            'q': -50,    # Black Queen\n",
    "            'K': 900,     # White King\n",
    "            'k': -900     # Black King\n",
    "    }\n",
    "    point=[10,20,30,40,50,900]\n",
    "    state = None\n",
    "    model = None\n",
    "    neg_r_each_step = -1\n",
    "    \n",
    "    def __init__(self, model: Sequential, ReplayMem: SequentialMemory, neg_r_each_step = -1, stockfishMem = True) -> None:\n",
    "        self.env = chess.Board()\n",
    "        self.ReplayMem = ReplayMem\n",
    "        self.model = model\n",
    "        self.lastest_move=[0,0]\n",
    "        self.state = self.reset()\n",
    "        self.neg_r_each_step = neg_r_each_step\n",
    "        self.stockfishMem = stockfishMem\n",
    "\n",
    "    def is_draw(self):\n",
    "        if self.env.is_stalemate():\n",
    "            print(\"statlemate\")\n",
    "            return True\n",
    "        if self.env.is_fivefold_repetition():\n",
    "            print(\"fivefold repetition\")\n",
    "            return True\n",
    "        if self.env.is_fifty_moves():\n",
    "            print(\"50 moves\")\n",
    "            return True\n",
    "        if self.env.is_insufficient_material():\n",
    "            print(\"Insufficient Material\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_checkmate(self):\n",
    "        # If There is checkmate then it will be TRUE else FALSE.It will be a boolean value.\n",
    "        return self.env.is_checkmate()\n",
    "\n",
    "    def convert_board_to_int(self):\n",
    "        epd_string = self.env.epd()\n",
    "        list_int = np.empty((0, ))\n",
    "        for i in epd_string:\n",
    "            if i == \" \":\n",
    "                list_int = list_int.reshape((8, 8))\n",
    "                return list_int\n",
    "            elif i != \"/\":\n",
    "                if i in self.mapped:\n",
    "                    list_int = np.append(list_int, self.mapped[i])\n",
    "                else:\n",
    "                    for counter in range(0, int(i)):\n",
    "                        list_int = np.append(list_int, 0)\n",
    "        list_int = list_int.reshape((8, 8))\n",
    "        return list_int\n",
    "\n",
    "    def get_state(self) -> np.ndarray:\n",
    "        square=self.convert_board_to_int()\n",
    "        x=np.zeros([8,8,8])\n",
    "        for i in range(6):\n",
    "            convert(x[i],square,self.point[i])\n",
    "        moves=self.legal_moves()\n",
    "        for move in moves:\n",
    "            a= move.from_square\n",
    "            b= move.to_square\n",
    "            x[6][7-int(a /8)][a%8]=-1\n",
    "            x[6][7-int(b /8)][b%8]=1\n",
    "        a=self.lastest_move[0]\n",
    "        b=self.lastest_move[1]\n",
    "        if a!=b:\n",
    "            x[7][7-a //8][a%8]=-1\n",
    "            x[7][7-b//8][b%8] =1   \n",
    "        else: \n",
    "            x[7]=[[0]*8 for i in range(8)]\n",
    "        return x   \n",
    "        \n",
    "\n",
    "    def legal_moves(self):\n",
    "        return list(self.env.legal_moves)\n",
    "\n",
    "    def legal_moves_encoded(self):\n",
    "        lg_encoded = []\n",
    "        for move in (self.env.legal_moves):\n",
    "            from_square = move.from_square\n",
    "            to_square = move.to_square\n",
    "            \n",
    "            lg_encoded.append(from_square * 64 + to_square)\n",
    "        return np.array(lg_encoded)\n",
    "\n",
    "    def encodeMove(self, move_uci:str):\n",
    "        a, b = chess.parse_square(move_uci[:2]), chess.parse_square(move_uci[2:])\n",
    "        return a * 64 + b\n",
    "\n",
    "    def decodeMove(self, move_int:int):\n",
    "        a, b = move_int//64, move_int%64\n",
    "        move = self.env.find_move(from_square= a,to_square= b)\n",
    "        return move\n",
    "\n",
    "    def render(self):\n",
    "        print(self.env.unicode())\n",
    "\n",
    "    def reset(self):\n",
    "        # random state\n",
    "        redo = True\n",
    "        num_sample_steps = 0\n",
    "        while redo:\n",
    "            redo = False\n",
    "            self.env = chess.Board()\n",
    "            num_sample_steps = np.random.randint(0, 4)\n",
    "            for i in range (num_sample_steps):\n",
    "                lg_move = self.legal_moves()\n",
    "                if len(lg_move) != 0:\n",
    "                    move = np.random.choice(self.legal_moves())\n",
    "                    self.env.push(move)\n",
    "                else:\n",
    "                    redo = True\n",
    "                    break\n",
    "            if len(self.legal_moves()) == 0:\n",
    "                redo = True\n",
    "\n",
    "        if len(self.env.move_stack) !=0:\n",
    "            self.lastest_move[0]= self.env.move_stack[-1].from_square\n",
    "            self.lastest_move[1]= self.env.move_stack[-1].to_square\n",
    "        else:\n",
    "            self.lastest_move[0]=0\n",
    "            self.lastest_move[1]=0\n",
    "        if self.env.turn == False:\n",
    "            self.env=self.env.mirror() \n",
    "            for i in range(2):\n",
    "                a=7-self.lastest_move[i]//8\n",
    "                b=self.lastest_move[i]%8\n",
    "                self.lastest_move[i]=8*a+b\n",
    "\n",
    "        self.state =  self.get_state()\n",
    "\n",
    "        Q_val = np.sort(self.model.predict(self.state.reshape((1, 1) + STATE_SHAPE)).reshape(-1, ))\n",
    "        print('Val', num_sample_steps, ':', Q_val[0],  Q_val[-1], Q_val[4050], Q_val[4000], Q_val[3000],Q_val[2000])\n",
    "        return self.state\n",
    "\n",
    "    def ifStockfishTurn(self) -> None:\n",
    "        done = False\n",
    "        reward = self.neg_r_each_step\n",
    "\n",
    "        stf_move = find_move(self)\n",
    "\n",
    "        # location to_square\n",
    "        to_r, to_c = 7 - stf_move.to_square//8, stf_move.to_square%8\n",
    "        try:\n",
    "            reward += self.point[np.where(self.state[:6, to_r, to_c ] != 0)[0][0]]\n",
    "        except:\n",
    "            reward += 0\n",
    "\n",
    "        # action\n",
    "        self.env.push(stf_move)\n",
    "\n",
    "        #convert turn\n",
    "        self.lastest_move[0]= self.env.move_stack[-1].from_square\n",
    "        self.lastest_move[1]= self.env.move_stack[-1].to_square \n",
    "        self.env=self.env.mirror() \n",
    "        \n",
    "        for i in range(2):\n",
    "            a=7-self.lastest_move[i]//8\n",
    "            b=self.lastest_move[i]%8\n",
    "            self.lastest_move[i]=8*a+b\n",
    "\n",
    "        pseudo_state = self.get_state()\n",
    "\n",
    "        # check end game\n",
    "        if self.is_checkmate():\n",
    "            reward += 900\n",
    "            done = True\n",
    "        elif self.is_draw():\n",
    "            reward += 300\n",
    "            done = True\n",
    "        # opponent's turn   \n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "            move = find_move(self)\n",
    "\n",
    "            # location to_square\n",
    "            to_r, to_c = 7 - move.to_square//8, move.to_square%8\n",
    "            try:\n",
    "                reward -= self.point[np.where(pseudo_state[:6, to_r, to_c ] != 0)[0][0]]\n",
    "            except:\n",
    "                reward -= 0\n",
    "\n",
    "            # action\n",
    "            self.env.push(move)\n",
    "            self.env=self.env.mirror() \n",
    "\n",
    "            # check end game\n",
    "            if self.is_checkmate():\n",
    "                reward -= 900\n",
    "                done = True\n",
    "            elif self.is_draw():\n",
    "                reward += 300\n",
    "                done = True\n",
    "\n",
    "        self.ReplayMem.append(self.state, stf_move.from_square * 64 + stf_move.to_square, reward, done)\n",
    "\n",
    "    def step(self, action: int):\n",
    "        reward = 0\n",
    "        done = True\n",
    "        \n",
    "        try:\n",
    "            # move in legal move\n",
    "            move = self.decodeMove(action)\n",
    "        except:\n",
    "            # wrong move\n",
    "            reward = -5000\n",
    "            done = True\n",
    "            print('wrong_move')\n",
    "\n",
    "            # add in memory action if it was stockfish\n",
    "            if self.stockfishMem:\n",
    "                self.ifStockfishTurn()\n",
    "\n",
    "            return self.state, reward, done, {}\n",
    "\n",
    "        # neg reward each step\n",
    "        reward = self.neg_r_each_step\n",
    "\n",
    "        # location to_square\n",
    "        to_r, to_c = 7 - move.to_square//8, move.to_square%8\n",
    "        try:\n",
    "            reward += self.point[np.where(self.state[:6, to_r, to_c ] != 0)[0][0]]\n",
    "        except:\n",
    "            reward += 0\n",
    "\n",
    "        # action\n",
    "        self.env.push(move)\n",
    "\n",
    "        #convert turn\n",
    "        self.lastest_move[0]= self.env.move_stack[-1].from_square\n",
    "        self.lastest_move[1]= self.env.move_stack[-1].to_square\n",
    "        self.env=self.env.mirror() \n",
    "        for i in range(2):\n",
    "            a=7-self.lastest_move[i]//8\n",
    "            b=self.lastest_move[i]%8\n",
    "            self.lastest_move[i]=8*a+b\n",
    "\n",
    "        self.state = self.get_state()\n",
    "\n",
    "        # check end game\n",
    "        if self.is_checkmate():\n",
    "            reward += 900\n",
    "            done = True\n",
    "            print('Win')\n",
    "        elif self.is_draw():\n",
    "            reward += 300\n",
    "            done = True\n",
    "\n",
    "        # opponent's turn   \n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "            move = find_move(self)\n",
    "\n",
    "            # location to_square\n",
    "            to_r, to_c = 7 - move.to_square//8, move.to_square%8\n",
    "            try:\n",
    "                reward -= self.point[np.where(self.state[:6, to_r, to_c ] != 0)[0][0]]\n",
    "            except:\n",
    "                reward -= 0\n",
    "\n",
    "            # action\n",
    "            self.env.push(move)\n",
    "\n",
    "            #convert turn\n",
    "            self.lastest_move[0]= self.env.move_stack[-1].from_square\n",
    "            self.lastest_move[1]= self.env.move_stack[-1].to_square \n",
    "            self.env=self.env.mirror() \n",
    "            for i in range(2):\n",
    "                a=7-self.lastest_move[i]//8\n",
    "                b=self.lastest_move[i]%8\n",
    "                self.lastest_move[i]=8*a+b\n",
    "\n",
    "            self.state = self.get_state()\n",
    "\n",
    "            # check end game\n",
    "            if self.is_checkmate():\n",
    "                reward -= 900\n",
    "                done = True\n",
    "                print('Lose')\n",
    "            elif self.is_draw():\n",
    "                reward += 300\n",
    "                done = True\n",
    "\n",
    "        # if reward != -5000: \n",
    "        #     reward += 10000\n",
    "\n",
    "        return self.state, reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalMovesPolicy(Policy):\n",
    "    \"\"\"Implement the epsilon greedy policy\n",
    "\n",
    "    Eps Greedy policy either:\n",
    "\n",
    "    - takes a random action with probability epsilon\n",
    "    - takes current best action with prob (1 - epsilon)\n",
    "    \"\"\"\n",
    "    def __init__(self, env: ChessEnv, eps=.1 , randomPer = .4, perLegal = 0.5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.env = env\n",
    "        self.randomPer = randomPer\n",
    "        self.perLegal = perLegal\n",
    "\n",
    "    def select_action(self, q_values):\n",
    "        \"\"\"Return the selected action\n",
    "\n",
    "        # Arguments\n",
    "            q_values (np.ndarray): List of the estimations of Q for each action\n",
    "\n",
    "        # Returns\n",
    "            Selection action\n",
    "        \"\"\"\n",
    "        assert q_values.ndim == 1\n",
    "        nb_actions = q_values.shape[0]\n",
    "\n",
    "        if len(self.env.legal_moves_encoded()) == 0:\n",
    "            print(\"not legal_movel\")\n",
    "            action = np.random.randint(0, nb_actions)\n",
    "\n",
    "        elif np.random.uniform() < self.eps:\n",
    "            if np.random.uniform() < self.randomPer:\n",
    "                action = np.random.randint(0, nb_actions)\n",
    "                \n",
    "            else:\n",
    "                action = np.random.choice(self.env.legal_moves_encoded())\n",
    "                \n",
    "        else:\n",
    "            if np.random.uniform() < self.perLegal:\n",
    "              idx_sorted = np.argsort(q_values)\n",
    "              for act in idx_sorted:\n",
    "                try:\n",
    "                    from_square, to_square = act//64, act%64                   \n",
    "                    self.env.env.find_move(from_square= from_square,to_square= to_square)\n",
    "                    action = act\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "              action = np.argmax(q_values)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and Mem\n",
    "memory = SequentialMemory(limit=10000, window_length=1)\n",
    "\n",
    "model = get_model888(STATE_SHAPE, NB_ACTIONS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE\n",
    "env = ChessEnv(model, memory, neg_r_each_step=-1, stockfishMem= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE\n",
    "# model.load_weights('superbot_888.h5')\n",
    "model.load_weights('drive/MyDrive/Data/Chess/superbot_888.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# # even the metrics!\n",
    "# memory = SequentialMemory(limit=10000, window_length=1)\n",
    "for i in range (10):\n",
    "  policy = LegalMovesPolicy(env, 0.1, 0.1, 0.99)\n",
    "  dqn = DQNAgent(model=model, nb_actions=NB_ACTIONS, memory=memory, batch_size = 16, gamma = 0.5, \n",
    "                #  enable_double_dqn = True, \n",
    "                target_model_update=1e-2, policy=policy, nb_steps_warmup = 500)\n",
    "  dqn.compile(Adam(lr=1e-1), metrics=['mae'])\n",
    "\n",
    "  his = dqn.fit(env, nb_steps=7500, visualize=False, verbose=2)\n",
    "  \n",
    "  #NOTE\n",
    "  model.save('superbot_888.h5')\n",
    "  !cp -r superbot_888.h5 /content/drive/MyDrive/Data/Chess\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
